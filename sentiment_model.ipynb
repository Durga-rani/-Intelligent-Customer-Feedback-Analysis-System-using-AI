from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification, Trainer, TrainingArguments
from sklearn.model_selection import train_test_split
from datasets import Dataset
import pandas as pd

# Load cleaned data
df = pd.read_csv('cleaned_feedback.csv')
df = df[df['sentiment'].isin(['Positive', 'Negative', 'Neutral'])]

# Encode labels
label_map = {'Positive': 0, 'Negative': 1, 'Neutral': 2}
df['label'] = df['sentiment'].map(label_map)

# Train-test split
train_texts, val_texts, train_labels, val_labels = train_test_split(df['cleaned_feedback'], df['label'], test_size=0.2)

# Tokenization
tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')
train_encodings = tokenizer(list(train_texts), truncation=True, padding=True)
val_encodings = tokenizer(list(val_texts), truncation=True, padding=True)

# Dataset formatting
train_dataset = Dataset.from_dict({**train_encodings, 'label': train_labels.tolist()})
val_dataset = Dataset.from_dict({**val_encodings, 'label': val_labels.tolist()})

# Model
model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=3)

# Training
training_args = TrainingArguments(output_dir='./results', evaluation_strategy="epoch", num_train_epochs=3)
trainer = Trainer(model=model, args=training_args, train_dataset=train_dataset, eval_dataset=val_dataset)
trainer.train()

# Save model
model.save_pretrained('./sentiment_model')
tokenizer.save_pretrained('./sentiment_model')
